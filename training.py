#!/usr/bin/env python
# coding: utf-8

# è¨“ç·´ ğŸ˜‰

# è¼‰å…¥å‡½å¼åº«


from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split 
from sklearn import tree
from sklearn import svm
from sklearn.metrics import accuracy_score
from collections import defaultdict
import pandas as pd
import data_generator


# è®€å…¥è³‡æ–™

df = pd.read_csv("data/student_data_30000.csv")
print(df.head())


# ç‰¹å¾µ

features = df.drop("Grade", axis=1)
features = pd.get_dummies(features, drop_first=True)
print(features.head())


# é¡åˆ¥

label = df["Grade"]
print(label.head())


# å°‡è³‡æ–™åˆ†æˆè¨“ç·´é›†(0.8)èˆ‡æ¸¬è©¦é›†(0.2)

X_train, X_test, y_train, y_test = train_test_split(features, label, test_size=0.20)


# Decision Tree ğŸŒ²

clf = tree.DecisionTreeClassifier(min_samples_split=2000, min_samples_leaf=1000, max_depth=8)
clf.fit(X_train, y_train)
pred_label = clf.predict(X_test)
print(accuracy_score(y_test, pred_label))


# Support Vector Machine ğŸ—¿

clf = svm.SVC(gamma='scale')
clf.fit(X_train, y_train)
pred_label = clf.predict(X_test)
accuracy_score(y_test, pred_label)
